# Детекция ненормативной лексики с помощью RuBERT-base

В этом проекте я использовала RuBERT для создания надежного классификатора для классификации текста на две категории: нормальный текст и ненорматвный. Проект включал обучение модели классификации последовательностей, оптимизацию гиперпараметров и эксперименты с различными методами предварительной обработки (аугментация русскими комментариями с https://kaspi.kz и исскуственным добавлением нецензурных слов, использование большой модели ruBert-large и более сложную предобработку данных). Наилучший результат, в моем случае, показала базовая модель без дополнения данных или сложной предварительной обработки, которая и представлена здесь.

## Основные характеристики

- `Предварительно обученная модель` я использовала **DeepPavlov/rubert-base-cased** для классификации последовательностей
-  `Токенизация` токенизированный входной текст c autotokenizer
- `Оптимизация гиперпараметров` использовала **Optuna** для настройки скорости обучения, количества шагов и эпох для оптимизации модели
- `Обработка дисбаланса классов` взвешенная loss function  для устранения несбалансированности классов в наборе данных
- `Оценка модели` F1 score

## Обучение модели

Обучение включало:

- Использование оптимизатора `AdamW` со скоростью обучения `6.6875e-06` 
- Планировщик для корректировки скорости обучения для повышения стабильности обучения `num warmup steps: 357`
- Эпохи обучения `3`

## Результаты

Лучшая версия модели без дополнительной аугментации или предварительной обработки показала следующие результаты:

- `Оценка валидации F1` **0,981**
- `Оценка теста F1` **0,980**
- `Оценка оригинального теста F1 на Kaggle` **0,9242**

## Файлы 

- [wb_winter_school_best_version.ipynb](https://github.com/avdtoto/wb_winter/wb_winter_school_best_version.ipynb) тетрадь с результатами 
- [submission.csv](https://github.com/avdtoto/wb_winter/submission.csv) прогнозы на оригинальном тестовом наборе

